{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmETbrrk6gJkbSpDwOwp9B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmtu14/ATM-/blob/main/English%20to%20french%20convert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5WPGnZjrIQw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbOK9xGMspqG",
        "outputId": "dc672970-1d49-4453-d43d-4d7ac7ec1cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_data = \"/content/drive/MyDrive/small_vocab_en.txt\"\n",
        "french_data = \"/content/drive/MyDrive/small_vocab_fr.txt\""
      ],
      "metadata": {
        "id": "P3Vp93DYspsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def load_data(path):\n",
        "  input_file = os.path.join(path)\n",
        "  with open(input_file,\"r\") as f:\n",
        "    data = f.read()\n",
        "    return data.split('\\n')\n"
      ],
      "metadata": {
        "id": "Y5LKnqYEspui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentences = load_data(english_data)\n",
        "french_sentences = load_data(french_data)"
      ],
      "metadata": {
        "id": "ch-1y6GospxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print('Sample:',i)\n",
        "  print(english_sentences[i])\n",
        "  print(french_sentences[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gciD4xEnsp0Z",
        "outputId": "b66b4c63-195e-4b0d-f0ef-26e26a3854e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: 0\n",
            "new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
            "new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
            "Sample: 1\n",
            "the united states is usually chilly during july , and it is usually freezing in november .\n",
            "les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
            "Sample: 2\n",
            "california is usually quiet during march , and it is usually hot in june .\n",
            "california est généralement calme en mars , et il est généralement chaud en juin .\n",
            "Sample: 3\n",
            "the united states is sometimes mild during june , and it is cold in september .\n",
            "les états-unis est parfois légère en juin , et il fait froid en septembre .\n",
            "Sample: 4\n",
            "your least liked fruit is the grape , but my least liked is the apple .\n",
            "votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections"
      ],
      "metadata": {
        "id": "QQjzGkJ6SZBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
        "print(english_words_counter)\n",
        "french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])\n",
        "print(french_words_counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2EtldyUSZMC",
        "outputId": "9f85604a-ece9-48ff-8af6-6adc5d65c00b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'is': 205858, ',': 140897, '.': 129039, 'in': 75525, 'it': 75137, 'during': 74933, 'the': 67628, 'but': 63987, 'and': 59850, 'sometimes': 37746, 'usually': 37507, 'never': 37500, 'least': 27564, 'favorite': 27371, 'fruit': 27105, 'most': 14934, 'loved': 13666, 'liked': 13546, 'new': 12197, 'paris': 11334, 'india': 11277, 'united': 11270, 'states': 11270, 'california': 11250, 'jersey': 11225, 'france': 11170, 'china': 10953, 'he': 10786, 'she': 10786, 'grapefruit': 10118, 'your': 9734, 'my': 9700, 'his': 9700, 'her': 9700, 'fall': 9134, 'june': 9133, 'spring': 9102, 'january': 9090, 'winter': 9038, 'march': 9023, 'autumn': 9004, 'may': 8995, 'nice': 8984, 'september': 8958, 'july': 8956, 'april': 8954, 'november': 8951, 'summer': 8948, 'december': 8945, 'february': 8942, 'our': 8932, 'their': 8932, 'freezing': 8928, 'pleasant': 8916, 'beautiful': 8915, 'october': 8910, 'snowy': 8898, 'warm': 8890, 'cold': 8878, 'wonderful': 8808, 'dry': 8794, 'busy': 8791, 'august': 8789, 'chilly': 8770, 'rainy': 8761, 'mild': 8743, 'wet': 8726, 'relaxing': 8696, 'quiet': 8693, 'hot': 8639, 'dislikes': 7314, 'likes': 7314, 'limes': 5554, 'mangoes': 5549, 'lemons': 5533, 'grapes': 5525, 'apples': 5452, 'oranges': 5452, 'strawberries': 5452, 'bananas': 5452, 'peaches': 5451, 'pears': 5451, 'to': 5166, 'strawberry': 4715, 'grape': 4703, 'lime': 4680, 'apple': 4652, 'lemon': 4652, 'banana': 4652, 'mango': 4652, 'pear': 4652, 'peach': 4652, 'orange': 4651, 'like': 4588, 'dislike': 4444, 'they': 3222, 'that': 2712, 'i': 2664, 'we': 2532, 'you': 2414, 'animal': 2304, 'a': 1944, 'truck': 1944, 'car': 1944, 'automobile': 1944, 'was': 1867, 'next': 1666, 'go': 1386, 'driving': 1296, 'visit': 1224, 'little': 1016, 'big': 1016, 'old': 972, 'yellow': 972, 'red': 972, 'rusty': 972, 'blue': 972, 'white': 972, 'black': 972, 'green': 972, 'shiny': 972, 'favorite.': 961, 'are': 870, '?': 811, 'last': 781, 'feared': 768, 'animals': 768, 'this': 768, 'plan': 714, 'going': 666, 'saw': 648, 'disliked': 648, 'drives': 648, 'drove': 648, 'grapefruit.': 574, 'between': 540, 'liked.': 500, 'loved.': 500, 'translate': 480, 'plans': 476, 'peaches.': 393, 'pears.': 393, 'bananas.': 392, 'oranges.': 392, 'apples.': 392, 'strawberries.': 392, 'were': 384, 'went': 378, 'might': 378, 'wanted': 378, 'thinks': 360, 'grapes.': 319, 'spanish': 312, 'portuguese': 312, 'chinese': 312, 'english': 312, 'french': 312, 'lemons.': 311, 'translating': 300, 'mangoes.': 295, 'limes.': 290, 'difficult': 260, 'fun': 260, 'easy': 260, 'wants': 252, 'think': 240, 'why': 240, \"it's\": 240, 'did': 204, 'orange.': 197, 'mango.': 196, 'banana.': 196, 'peach.': 196, 'lemon.': 196, 'pear.': 196, 'apple.': 196, 'cat': 192, 'shark': 192, 'bird': 192, 'mouse': 192, 'horse': 192, 'elephant': 192, 'dog': 192, 'monkey': 192, 'lion': 192, 'bear': 192, 'rabbit': 192, 'snake': 192, 'lime.': 168, 'grape.': 145, 'when': 144, 'strawberry.': 133, 'want': 126, 'fruit.': 87, 'do': 84, 'how': 67, 'elephants': 64, 'horses': 64, 'dogs': 64, 'sharks': 64, 'snakes': 64, 'cats': 64, 'rabbits': 64, 'monkeys': 64, 'bears': 64, 'birds': 64, 'lions': 64, 'mice': 64, \"didn't\": 60, 'eiffel': 57, 'tower': 57, 'grocery': 57, 'store': 57, 'football': 57, 'field': 57, 'lake': 57, 'school': 57, 'would': 48, \"aren't\": 36, 'been': 36, 'weather': 33, 'does': 24, 'has': 24, \"isn't\": 24, 'am': 24, 'where': 12, 'have': 12})\n",
            "Counter({'est': 196809, '.': 135619, ',': 123135, 'en': 105768, 'il': 84079, 'les': 65255, 'mais': 63987, 'et': 59851, 'la': 49861, 'parfois': 37746, 'jamais': 37215, 'le': 35306, \"l'\": 32917, 'généralement': 31292, 'moins': 27557, 'au': 25738, 'aimé': 24842, 'fruit': 23626, 'préféré': 22886, 'agréable': 17751, 'froid': 16794, 'son': 16496, 'chaud': 16405, 'de': 15070, 'plus': 14934, 'automne': 14727, 'mois': 14350, 'à': 13870, 'elle': 12056, 'citrons': 11679, 'paris': 11334, 'inde': 11277, 'états-unis': 11210, 'france': 11170, 'jersey': 11052, 'new': 11047, 'chine': 10936, 'pendant': 10741, 'pamplemousse': 10140, 'mon': 9403, 'votre': 9368, 'juin': 9133, 'printemps': 9100, 'janvier': 9090, 'hiver': 9038, 'mars': 9023, 'été': 8999, 'mai': 8995, 'septembre': 8958, 'juillet': 8956, 'avril': 8954, 'novembre': 8951, 'décembre': 8945, 'février': 8942, 'octobre': 8911, 'aime': 8870, 'août': 8789, 'merveilleux': 8704, 'relaxant': 8458, 'doux': 8458, 'humide': 8446, 'notre': 8319, 'californie': 8189, 'sec': 7957, 'leur': 7855, 'occupé': 7782, 'pluvieux': 7658, 'calme': 7256, 'beau': 6387, 'habituellement': 6215, 'pommes': 5844, 'pêches': 5844, 'oranges': 5844, 'poires': 5844, 'fraises': 5844, 'bananes': 5844, 'verts': 5835, 'raisins': 5780, 'mangues': 5774, \"d'\": 5100, 'mangue': 4899, 'gel': 4886, 'raisin': 4852, 'pomme': 4848, \"l'orange\": 4848, 'citron': 4848, 'chaux': 4848, 'banane': 4848, 'poire': 4848, 'fraise': 4848, 'pêche': 4848, 'pas': 4495, 'enneigée': 4008, 'favori': 3857, 'déteste': 3743, 'gèle': 3622, 'fruits': 3566, 'voiture': 3510, \"l'automne\": 3411, 'ils': 3185, \"n'aime\": 3131, 'california': 3061, 'neige': 3016, 'fait': 2916, 'belle': 2726, 'ne': 2715, 'nous': 2520, 'vous': 2517, 'des': 2435, 'animal': 2248, 'camion': 1944, 'cours': 1927, 'neigeux': 1867, 'conduit': 1706, 'prochain': 1666, 'je': 1548, 'ce': 1465, 'tranquille': 1437, 'a': 1356, 'cher': 1308, 'une': 1278, 'cette': 1239, 'était': 1198, 'aller': 1180, 'chaude': 1124, 'aiment': 1116, 'aimons': 1111, \"n'aiment\": 1111, \"n'aimez\": 1094, 'leurs': 1072, 'aimez': 1053, 'sont': 1018, 'aimé.': 1010, 'détestons': 1001, 'jaune': 972, 'rouge': 972, \"j'aime\": 966, 'visiter': 908, 'sèche': 837, 'occupée': 836, 'frisquet': 834, '?': 811, 'préférée': 770, 'animaux': 768, 'dernier': 757, 'aimait': 707, 'un': 698, 'conduisait': 673, 'que': 667, 'nouvelle': 648, 'vieille': 647, 'vu': 645, 'verte': 628, 'petite': 615, 'nos': 613, 'noire': 602, 'brillant': 587, 'blanche': 579, 'redouté': 576, 'pleut': 562, \"n'aimait\": 561, 'pamplemousses': 552, 'pense': 540, 'entre': 540, 'bleue': 504, 'nouveau': 502, 'traduire': 501, 'rouillée': 486, 'bleu': 468, 'se': 461, 'grande': 459, 'rouillé': 454, 'préféré.': 419, 'ses': 402, \"qu'il\": 393, 'blanc': 393, 'aux': 392, 'brillante': 385, 'préférés': 383, 'noir': 370, 'pluies': 367, 'envisage': 360, 'étaient': 357, 'va': 355, 'rendre': 350, 'vert': 344, '-': 328, 'vieux': 325, 'petit': 324, 'espagnol': 312, 'portugais': 312, 'chinois': 312, 'anglais': 312, 'français': 312, 'glaciales': 307, 'mes': 297, 'cet': 286, 'automobile': 278, 'traduction': 277, 'mouillé': 273, 'difficile': 260, 'amusant': 260, 'facile': 260, 'comme': 259, 'gros': 258, 'souris': 256, 'pourrait': 252, 'voulait': 252, 'veut': 252, 'pourquoi': 240, 'aimés': 237, 'prévois': 233, 'prévoyons': 232, 'vos': 225, 'intention': 206, 'clémentes': 200, 'ont': 194, 'chat': 192, 'requin': 192, 'cheval': 192, 'chien': 192, 'singe': 192, 'lion': 192, 'ours': 192, 'lapin': 192, 'serpent': 192, 'redoutés': 190, 'allé': 187, 'grosse': 185, 'pluie': 174, 'trop': 173, 'monde': 173, 'maillot': 173, 'vont': 168, 'volant': 165, 'avez': 162, 'i': 150, 'allés': 150, 'allée': 150, 'quand': 144, 'oiseau': 128, 'éléphant': 128, 'pourraient': 126, 'voulaient': 126, 'veulent': 126, 'détendre': 111, 'aimée': 105, 'magnifique': 104, \"l'automobile\": 100, \"n'aimons\": 97, '-ce': 95, 'gelé': 94, 'détestait': 87, 'grand': 81, 'bien': 77, 'vers': 76, 'prévoient': 75, 'prévoit': 75, 'lui': 70, 'visite': 68, 'comment': 67, 'éléphants': 64, 'chevaux': 64, 'chiens': 64, \"l'éléphant\": 64, \"l'oiseau\": 64, 'requins': 64, \"l'ours\": 64, 'serpents': 64, 'chats': 64, 'lapins': 64, 'singes': 64, 'oiseaux': 64, 'lions': 64, 'légère': 63, 'cépage': 60, 'pensez': 60, 'États-unis': 57, 'tour': 57, 'eiffel': 57, \"l'épicerie\": 57, 'terrain': 57, 'football': 57, 'lac': 57, \"l'école\": 57, \"l'animal\": 56, \"n'est\": 47, 'allons': 45, 'allez': 45, 'peu': 41, 'pousse': 41, 'du': 39, '-il': 36, 'temps': 33, 'at': 32, 'rouille': 32, 'sur': 28, \"qu'elle\": 26, '-ils': 26, 'petites': 26, '-elle': 24, 'dernière': 24, 'êtes-vous': 24, 'vais': 24, 'voudrait': 24, 'proches': 20, 'frais': 20, 'manguiers': 19, 'avons': 19, 't': 18, 'porcelaine': 17, 'détestez': 17, \"c'est\": 17, 'grandes': 16, 'préférées': 16, 'douce': 14, 'durant': 14, 'congélation': 14, 'plaît': 13, 'où': 12, 'dans': 12, 'est-ce': 12, 'voulez': 12, 'aimeraient': 12, \"n'a\": 12, 'petits': 10, 'aiment-ils': 10, 'grands': 9, 'limes': 9, 'envisagent': 9, 'grosses': 8, 'bénigne': 8, 'mouillée': 7, 'enneigé': 7, 'moindres': 7, 'conduite': 6, 'gelés': 5, 'tout': 4, 'etats-unis': 3, \"n'êtes\": 3, 'vit': 3, 'ressort': 2, 'détend': 2, 'redoutée': 2, 'qui': 2, 'traduis': 2, 'apprécié': 2, 'allions': 1, 'trouvé': 1, 'as-tu': 1, 'faire': 1, 'favoris': 1, 'souvent': 1, 'es-tu': 1, 'moteur': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(x):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(x)\n",
        "  return tokenizer.texts_to_sequences(x), tokenizer"
      ],
      "metadata": {
        "id": "BHKZX4nHSZVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_sentences = [\n",
        "    'the quick brown fox jumps obver the lazy dog',\n",
        "    'by love, my quck study of prize',\n",
        "    'This is a short sentence'\n",
        "]\n",
        "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
        "print(text_tokenizer.word_index)\n",
        "print()\n",
        "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences,text_tokenized)):\n",
        "  print('Sequence {} in x'.format(sample_i+1))\n",
        "  print('Input {}'.format(sent))\n",
        "  print('Output{}'.format(token_sent))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_pojINwSZXj",
        "outputId": "7f812b7c-9272-412c-8f65-7c735a4263ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 1, 'quick': 2, 'brown': 3, 'fox': 4, 'jumps': 5, 'obver': 6, 'lazy': 7, 'dog': 8, 'by': 9, 'love': 10, 'my': 11, 'quck': 12, 'study': 13, 'of': 14, 'prize': 15, 'this': 16, 'is': 17, 'a': 18, 'short': 19, 'sentence': 20}\n",
            "\n",
            "Sequence 1 in x\n",
            "Input the quick brown fox jumps obver the lazy dog\n",
            "Output[1, 2, 3, 4, 5, 6, 1, 7, 8]\n",
            "Sequence 2 in x\n",
            "Input by love, my quck study of prize\n",
            "Output[9, 10, 11, 12, 13, 14, 15]\n",
            "Sequence 3 in x\n",
            "Input This is a short sentence\n",
            "Output[16, 17, 18, 19, 20]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad(x, length=None):\n",
        "  return pad_sequences(x, maxlen=length, padding='post')\n"
      ],
      "metadata": {
        "id": "5xjD0ZxOSZZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(x,y):\n",
        "  preprocess_x, x_tk = tokenize(x)\n",
        "  preprocess_y, y_tk = tokenize(y)\n",
        "  preprocess_x = pad(preprocess_x)\n",
        "  preprocess_y = pad(preprocess_y)\n",
        "  preprocess_y = preprocess_y.reshape(*preprocess_y.shape,1)\n",
        "  return preprocess_x,preprocess_y,x_tk,y_tk\n",
        "\n",
        "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer = \\\n",
        "preprocess(english_sentences, french_sentences)\n",
        "\n",
        "max_english_sequence_legth = preproc_english_sentences.shape[1]\n",
        "max_french_sequence_legth = preproc_french_sentences.shape[1]\n",
        "english_vocab_size = len(english_tokenizer.word_index)\n",
        "french_vocab_size = len(french_tokenizer.word_index)\n",
        "print(max_english_sequence_legth)\n",
        "print(max_french_sequence_legth)\n",
        "print(english_vocab_size)\n",
        "print(french_vocab_size)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47yF0HhcSZc1",
        "outputId": "a6065b52-f01f-4fdb-ea55-25cebc4a49c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "21\n",
            "199\n",
            "344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def logits_to_text(logits,tokenizer):\n",
        "  index_to_words = {id:word for word, id in tokenizer.word_index.items()}\n",
        "  index_to_words[0] = '<PAD>'\n",
        "  return ''.join([index_to_words[prediction] for prediction in np.argmax(logits,1)])"
      ],
      "metadata": {
        "id": "8sWD0qLdbBaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, TimeDistributed, Dense, Dropout\n",
        "\n",
        "def embed_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    learning_rate = 0.005\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(english_vocab_size, 256, input_length=input_shape[1], input_shape=input_shape[1:]))\n",
        "    model.add(GRU(256, return_sequences=True))\n",
        "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax')))\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Dun1uNlpbBdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\n",
        "tmp_x = tmp_x.reshape(-1, preproc_french_sentences.shape[-2])"
      ],
      "metadata": {
        "id": "JhwIab9gbBfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_rnn_model = embed_model(\n",
        "    tmp_x.shape,\n",
        "    preproc_french_sentences.shape[1],\n",
        "    len(english_tokenizer.word_index)+1,\n",
        "    len(french_tokenizer.word_index)+1)"
      ],
      "metadata": {
        "id": "aGhZaqJ5bBiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_rnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noCnv2bhbBlq",
        "outputId": "1ad8af7b-d460-4c40-c041-3f43719a9773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 21, 256)           51200     \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 21, 256)           394752    \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 21, 1024)          263168    \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 21, 1024)          0         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDi  (None, 21, 345)           353625    \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1062745 (4.05 MB)\n",
            "Trainable params: 1062745 (4.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=simple_rnn_model.fit(tmp_x,preproc_french_sentences,batch_size=1024,epochs=20,validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8Ue27JUbBpH",
        "outputId": "75eaefe8-9e9e-477d-a975-7ba22ee415eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "108/108 [==============================] - 444s 4s/step - loss: 1.3704 - accuracy: 0.6809 - val_loss: 0.4911 - val_accuracy: 0.8436\n",
            "Epoch 2/20\n",
            "108/108 [==============================] - 418s 4s/step - loss: 0.4128 - accuracy: 0.8655 - val_loss: 0.3038 - val_accuracy: 0.8985\n",
            "Epoch 3/20\n",
            "108/108 [==============================] - 389s 4s/step - loss: 0.2965 - accuracy: 0.9014 - val_loss: 0.2534 - val_accuracy: 0.9124\n",
            "Epoch 4/20\n",
            "108/108 [==============================] - 382s 4s/step - loss: 0.2460 - accuracy: 0.9168 - val_loss: 0.2168 - val_accuracy: 0.9249\n",
            "Epoch 5/20\n",
            "108/108 [==============================] - 391s 4s/step - loss: 0.2231 - accuracy: 0.9236 - val_loss: 0.2047 - val_accuracy: 0.9291\n",
            "Epoch 6/20\n",
            "108/108 [==============================] - 403s 4s/step - loss: 0.2055 - accuracy: 0.9288 - val_loss: 0.1956 - val_accuracy: 0.9316\n",
            "Epoch 7/20\n",
            "108/108 [==============================] - 398s 4s/step - loss: 0.1975 - accuracy: 0.9310 - val_loss: 0.1881 - val_accuracy: 0.9345\n",
            "Epoch 8/20\n",
            "108/108 [==============================] - 400s 4s/step - loss: 0.1889 - accuracy: 0.9336 - val_loss: 0.1845 - val_accuracy: 0.9350\n",
            "Epoch 9/20\n",
            "108/108 [==============================] - 405s 4s/step - loss: 0.1853 - accuracy: 0.9345 - val_loss: 0.1846 - val_accuracy: 0.9363\n",
            "Epoch 10/20\n",
            "108/108 [==============================] - 404s 4s/step - loss: 0.1795 - accuracy: 0.9360 - val_loss: 0.1829 - val_accuracy: 0.9360\n",
            "Epoch 11/20\n",
            "108/108 [==============================] - 406s 4s/step - loss: 0.1802 - accuracy: 0.9357 - val_loss: 0.1827 - val_accuracy: 0.9351\n",
            "Epoch 12/20\n",
            "108/108 [==============================] - 408s 4s/step - loss: 0.1754 - accuracy: 0.9370 - val_loss: 0.1765 - val_accuracy: 0.9377\n",
            "Epoch 13/20\n",
            "108/108 [==============================] - 395s 4s/step - loss: 0.1719 - accuracy: 0.9379 - val_loss: 0.1772 - val_accuracy: 0.9377\n",
            "Epoch 14/20\n",
            "108/108 [==============================] - 400s 4s/step - loss: 0.1685 - accuracy: 0.9386 - val_loss: 0.1768 - val_accuracy: 0.9381\n",
            "Epoch 15/20\n",
            "108/108 [==============================] - 394s 4s/step - loss: 0.1664 - accuracy: 0.9392 - val_loss: 0.1749 - val_accuracy: 0.9389\n",
            "Epoch 16/20\n",
            "108/108 [==============================] - 398s 4s/step - loss: 0.1645 - accuracy: 0.9395 - val_loss: 0.1812 - val_accuracy: 0.9375\n",
            "Epoch 17/20\n",
            "108/108 [==============================] - 411s 4s/step - loss: 0.1718 - accuracy: 0.9378 - val_loss: 0.1830 - val_accuracy: 0.9361\n",
            "Epoch 18/20\n",
            "108/108 [==============================] - 407s 4s/step - loss: 0.1709 - accuracy: 0.9380 - val_loss: 0.1795 - val_accuracy: 0.9378\n",
            "Epoch 19/20\n",
            "108/108 [==============================] - 390s 4s/step - loss: 0.1718 - accuracy: 0.9378 - val_loss: 0.1782 - val_accuracy: 0.9386\n",
            "Epoch 20/20\n",
            "108/108 [==============================] - 400s 4s/step - loss: 0.1643 - accuracy: 0.9396 - val_loss: 0.1768 - val_accuracy: 0.9390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simple_rnn_model.save('model.h5')"
      ],
      "metadata": {
        "id": "Ea13XVinkQUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_tokenizer.word_index"
      ],
      "metadata": {
        "id": "5RuLmNOxkQXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def final_predictions(text):\n",
        " y_id_to_word = {value:key for key , value in french_tokenizer.word_index.items()}\n",
        " y_id_to_word[0] = '<PAD>'\n",
        " sentence = [english_tokenizer.word_index[word] for word in text.split()]\n",
        " sentence = pad_sequences([sentence], maxlen=preproc_french_sentences.shape[-2],padding='post')\n",
        " text1 = logits_to_text(simple_rnn_model.predict(sentence[:1][0],french_tokenizer))\n",
        " text2=\"\"\n",
        " for i in text1.split():\n",
        "  if i =='<PAD>':\n",
        "    break\n",
        "  else:\n",
        "    text2=text2+\" \"+i\n",
        "\n",
        "  return text2\n",
        "\n"
      ],
      "metadata": {
        "id": "5Y6zfGN4kQZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_predictions(input())"
      ],
      "metadata": {
        "id": "c0ce9gTXkQb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZfpyqrcSkQe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Q-8zR0ekQik"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}